#!/usr/bin/env python3
"""
MONITORING & REPORTING AGENT - Chat-G.txt Section 7
Mission: Daily P&L attribution and performance dashboards
"""

import pandas as pd
import numpy as np
from pathlib import Path
import logging
import json
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any
import warnings
warnings.filterwarnings('ignore')

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MonitoringReportingAgent:
    """
    Monitoring & Reporting Agent - Chat-G.txt Section 7
    Daily P&L attribution and performance dashboards
    """
    
    def __init__(self, trading_config: Dict):
        logger.info("üìä MONITORING & REPORTING AGENT - PERFORMANCE DASHBOARDS")
        
        self.config = trading_config
        self.base_dir = Path(__file__).parent.parent
        self.artifacts_dir = self.base_dir / "artifacts"
        
        # Reporting configuration
        self.reporting_config = trading_config.get('reporting', {})
        
        logger.info("üìà Reporting Configuration:")
        logger.info(f"   Daily Reports: {self.reporting_config.get('daily_reports', True)}")
        logger.info(f"   Performance Attribution: {self.reporting_config.get('performance_attribution', True)}")
        logger.info(f"   Risk Analytics: {self.reporting_config.get('risk_analytics', True)}")
        
    def generate_daily_report(self, date: Optional[str] = None) -> Dict[str, Any]:
        """
        Generate comprehensive daily performance report
        DoD: All KPIs tracked, P&L attribution, alerts for anomalies
        """
        
        if date is None:
            date = datetime.now().strftime('%Y-%m-%d')
        
        logger.info(f"üìä Generating daily report for {date}...")
        
        try:
            # Load portfolio data
            portfolio_data = self._load_portfolio_performance_data(date)
            
            # Generate performance metrics
            performance_metrics = self._calculate_performance_metrics(portfolio_data, date)
            
            # P&L attribution analysis
            pnl_attribution = self._calculate_pnl_attribution(portfolio_data, date)
            
            # Risk analytics
            risk_analytics = self._calculate_risk_analytics(portfolio_data, date)
            
            # Model performance tracking
            model_performance = self._track_model_performance(date)
            
            # Generate alerts
            alerts = self._generate_alerts(performance_metrics, risk_analytics)
            
            # Create comprehensive report
            daily_report = {
                'date': date,
                'performance_metrics': performance_metrics,
                'pnl_attribution': pnl_attribution,
                'risk_analytics': risk_analytics,
                'model_performance': model_performance,
                'alerts': alerts,
                'timestamp': datetime.now().isoformat()
            }
            
            # Save report artifacts
            self._save_daily_report(daily_report)
            
            # Generate dashboard
            self._generate_dashboard(daily_report)
            
            logger.info("‚úÖ Daily report generated successfully")
            return daily_report
            
        except Exception as e:
            logger.error(f"‚ùå Daily report generation failed: {e}")
            import traceback
            traceback.print_exc()
            return {'success': False, 'error': str(e)}
    
    def _load_portfolio_performance_data(self, date: str) -> Optional[Dict[str, pd.DataFrame]]:
        """Load portfolio and performance data for reporting"""
        
        logger.info("üìÇ Loading portfolio performance data...")
        
        portfolio_data = {}
        
        # Load current portfolio
        portfolio_dir = self.artifacts_dir / "portfolios"
        if portfolio_dir.exists():
            portfolio_files = list(portfolio_dir.glob("portfolio_*.parquet"))
            if portfolio_files:
                portfolio_files.sort()
                latest_portfolio = pd.read_parquet(portfolio_files[-1])
                portfolio_data['current_portfolio'] = latest_portfolio
        
        # Load historical portfolios for comparison
        if len(portfolio_files) > 1:
            previous_portfolio = pd.read_parquet(portfolio_files[-2])
            portfolio_data['previous_portfolio'] = previous_portfolio
        
        # Load execution data
        execution_files = list(portfolio_dir.glob("execution_plan_*.parquet"))
        if execution_files:
            execution_files.sort()
            latest_execution = pd.read_parquet(execution_files[-1])
            portfolio_data['execution_plan'] = latest_execution
        
        # Simulate market data (in production, would load real price data)
        if 'current_portfolio' in portfolio_data:
            tickers = portfolio_data['current_portfolio']['Ticker'].tolist()
            market_data = self._simulate_market_data(tickers, date)
            portfolio_data['market_data'] = market_data
        
        logger.info(f"‚úÖ Loaded portfolio data: {list(portfolio_data.keys())}")
        return portfolio_data if portfolio_data else None
    
    def _simulate_market_data(self, tickers: List[str], date: str) -> pd.DataFrame:
        """Simulate market data for reporting (placeholder for real data)"""
        
        # In production, would fetch real market data
        np.random.seed(42)  # For reproducible results
        
        market_data = []
        for ticker in tickers:
            # Simulate daily return
            daily_return = np.random.normal(0, 0.02)  # 2% daily vol
            
            market_data.append({
                'Ticker': ticker,
                'Date': date,
                'daily_return': daily_return,
                'price': 100 * (1 + daily_return),  # Arbitrary base price
                'volume': np.random.uniform(1e6, 10e6)
            })
        
        return pd.DataFrame(market_data)
    
    def _calculate_performance_metrics(self, portfolio_data: Dict, date: str) -> Dict[str, float]:
        """Calculate comprehensive performance metrics"""
        
        logger.info("üìà Calculating performance metrics...")
        
        if not portfolio_data or 'current_portfolio' not in portfolio_data:
            return {'error': 'No portfolio data available'}
        
        current_portfolio = portfolio_data['current_portfolio']
        market_data = portfolio_data.get('market_data')
        
        # Calculate daily P&L
        if market_data is not None:
            # Merge portfolio with market data
            pnl_data = current_portfolio.merge(market_data, on='Ticker', how='left')
            
            # Calculate position P&L
            portfolio_value = 10_000_000  # $10M assumption
            pnl_data['position_value'] = pnl_data['weight'] * portfolio_value
            pnl_data['position_pnl'] = pnl_data['position_value'] * pnl_data['daily_return'].fillna(0)
            
            # Aggregate metrics
            total_pnl = pnl_data['position_pnl'].sum()
            daily_return = total_pnl / portfolio_value
            
            # Long/short attribution
            long_pnl = pnl_data[pnl_data['weight'] > 0]['position_pnl'].sum()
            short_pnl = pnl_data[pnl_data['weight'] < 0]['position_pnl'].sum()
            
        else:
            # Placeholder if no market data
            total_pnl = np.random.normal(0, 50000)  # Random daily P&L
            daily_return = total_pnl / 10_000_000
            long_pnl = total_pnl * 0.6
            short_pnl = total_pnl * 0.4
        
        # Portfolio exposure metrics
        gross_exposure = np.abs(current_portfolio['weight']).sum()
        net_exposure = current_portfolio['weight'].sum()
        
        # Position count
        num_positions = len(current_portfolio)
        num_long = (current_portfolio['weight'] > 0).sum()
        num_short = (current_portfolio['weight'] < 0).sum()
        
        # Turnover (if previous portfolio available)
        if 'previous_portfolio' in portfolio_data:
            prev_portfolio = portfolio_data['previous_portfolio']
            # Merge current and previous for turnover calculation
            turnover_data = current_portfolio[['Ticker', 'weight']].merge(
                prev_portfolio[['Ticker', 'weight']], 
                on='Ticker', 
                how='outer', 
                suffixes=('_current', '_prev')
            ).fillna(0)
            
            daily_turnover = np.abs(turnover_data['weight_current'] - turnover_data['weight_prev']).sum()
        else:
            daily_turnover = 0
        
        metrics = {
            'total_pnl': total_pnl,
            'daily_return_pct': daily_return * 100,
            'long_pnl': long_pnl,
            'short_pnl': short_pnl,
            'gross_exposure': gross_exposure,
            'net_exposure': net_exposure,
            'daily_turnover': daily_turnover,
            'num_positions': num_positions,
            'num_long': num_long,
            'num_short': num_short,
            'largest_position': np.abs(current_portfolio['weight']).max(),
            'portfolio_value': 10_000_000  # Assumption
        }
        
        logger.info(f"üìä Performance Summary:")
        logger.info(f"   Daily P&L: ${total_pnl:,.0f} ({daily_return*100:+.2f}%)")
        logger.info(f"   Gross Exposure: {gross_exposure:.1%}")
        logger.info(f"   Positions: {num_long} long, {num_short} short")
        logger.info(f"   Daily Turnover: {daily_turnover:.1%}")
        
        return metrics
    
    def _calculate_pnl_attribution(self, portfolio_data: Dict, date: str) -> Dict[str, Any]:
        """Calculate detailed P&L attribution"""
        
        logger.info("üîç Calculating P&L attribution...")
        
        if not portfolio_data or 'current_portfolio' not in portfolio_data:
            return {'error': 'No portfolio data available'}
        
        current_portfolio = portfolio_data['current_portfolio']
        market_data = portfolio_data.get('market_data')
        
        attribution = {}
        
        if market_data is not None:
            # Merge data
            attr_data = current_portfolio.merge(market_data, on='Ticker', how='left')
            attr_data['daily_return'] = attr_data['daily_return'].fillna(0)
            
            portfolio_value = 10_000_000
            attr_data['position_value'] = attr_data['weight'] * portfolio_value
            attr_data['position_pnl'] = attr_data['position_value'] * attr_data['daily_return']
            
            # Attribution by sector
            if 'sector' in attr_data.columns:
                sector_attribution = attr_data.groupby('sector')['position_pnl'].sum().to_dict()
                attribution['by_sector'] = sector_attribution
            
            # Attribution by position size
            attr_data['size_bucket'] = pd.cut(
                np.abs(attr_data['weight']), 
                bins=[0, 0.01, 0.02, 0.05, 1.0],
                labels=['Small', 'Medium', 'Large', 'XLarge']
            )
            size_attribution = attr_data.groupby('size_bucket')['position_pnl'].sum().to_dict()
            attribution['by_position_size'] = {str(k): v for k, v in size_attribution.items()}
            
            # Top contributors and detractors
            top_contributors = attr_data.nlargest(5, 'position_pnl')[['Ticker', 'position_pnl']].to_dict('records')
            top_detractors = attr_data.nsmallest(5, 'position_pnl')[['Ticker', 'position_pnl']].to_dict('records')
            
            attribution['top_contributors'] = top_contributors
            attribution['top_detractors'] = top_detractors
            
            # Long vs Short attribution
            long_pnl = attr_data[attr_data['weight'] > 0]['position_pnl'].sum()
            short_pnl = attr_data[attr_data['weight'] < 0]['position_pnl'].sum()
            
            attribution['long_short'] = {
                'long_pnl': long_pnl,
                'short_pnl': short_pnl,
                'long_contribution_pct': (long_pnl / (long_pnl + short_pnl)) * 100 if (long_pnl + short_pnl) != 0 else 0
            }
        
        else:
            # Placeholder attribution
            attribution = {
                'by_sector': {'Technology': 25000, 'Healthcare': -10000, 'Finance': 15000},
                'by_position_size': {'Large': 20000, 'Medium': 10000, 'Small': 0},
                'top_contributors': [{'Ticker': 'AAPL', 'position_pnl': 15000}],
                'top_detractors': [{'Ticker': 'TSLA', 'position_pnl': -8000}],
                'long_short': {'long_pnl': 30000, 'short_pnl': 0, 'long_contribution_pct': 100}
            }
        
        logger.info("‚úÖ P&L attribution completed")
        return attribution
    
    def _calculate_risk_analytics(self, portfolio_data: Dict, date: str) -> Dict[str, Any]:
        """Calculate risk analytics and metrics"""
        
        logger.info("‚öñÔ∏è Calculating risk analytics...")
        
        if not portfolio_data or 'current_portfolio' not in portfolio_data:
            return {'error': 'No portfolio data available'}
        
        current_portfolio = portfolio_data['current_portfolio']
        
        # Portfolio risk metrics
        risk_metrics = {
            'gross_exposure': np.abs(current_portfolio['weight']).sum(),
            'net_exposure': current_portfolio['weight'].sum(),
            'num_positions': len(current_portfolio),
            'largest_position': np.abs(current_portfolio['weight']).max(),
            'portfolio_beta': 1.0,  # Placeholder - would calculate from real data
            'estimated_daily_vol': 0.015,  # Placeholder - 1.5% daily vol
        }
        
        # Sector concentration
        if 'sector' in current_portfolio.columns:
            sector_exposures = current_portfolio.groupby('sector')['weight'].sum()
            risk_metrics['max_sector_exposure'] = np.abs(sector_exposures).max()
            risk_metrics['sector_count'] = len(sector_exposures)
        
        # Position concentration
        position_sizes = np.abs(current_portfolio['weight'])
        risk_metrics['top5_concentration'] = position_sizes.nlargest(5).sum()
        risk_metrics['top10_concentration'] = position_sizes.nlargest(10).sum()
        
        # Risk limit utilization
        risk_limits = self.config.get('risk_limits', {})
        risk_utilization = {}
        
        if 'max_position_size' in risk_limits:
            risk_utilization['position_size'] = risk_metrics['largest_position'] / risk_limits['max_position_size']
        
        if 'max_leverage' in risk_limits:
            risk_utilization['leverage'] = risk_metrics['gross_exposure'] / risk_limits['max_leverage']
        
        if 'max_sector_exposure' in risk_limits and 'max_sector_exposure' in risk_metrics:
            risk_utilization['sector_exposure'] = risk_metrics['max_sector_exposure'] / risk_limits['max_sector_exposure']
        
        analytics = {
            'risk_metrics': risk_metrics,
            'risk_utilization': risk_utilization,
            'risk_score': np.mean(list(risk_utilization.values())) if risk_utilization else 0
        }
        
        logger.info(f"‚öñÔ∏è Risk Summary:")
        logger.info(f"   Risk Score: {analytics['risk_score']:.2%}")
        logger.info(f"   Largest Position: {risk_metrics['largest_position']:.2%}")
        logger.info(f"   Gross Exposure: {risk_metrics['gross_exposure']:.1%}")
        
        return analytics
    
    def _track_model_performance(self, date: str) -> Dict[str, Any]:
        """Track model performance and prediction accuracy"""
        
        logger.info("ü§ñ Tracking model performance...")
        
        # Load model results
        model_results_path = self.artifacts_dir / "models" / "lgbm_results.json"
        
        if not model_results_path.exists():
            return {'error': 'No model results available'}
        
        with open(model_results_path, 'r') as f:
            model_results = json.load(f)
        
        # Extract model performance metrics
        cv_results = model_results.get('cv_results', {})
        walkforward_results = model_results.get('walkforward_results', {})
        
        model_performance = {
            'model_name': model_results.get('model_name', 'unknown'),
            'oof_ic': cv_results.get('oof_ic', 0),
            'newey_west_tstat': cv_results.get('newey_west_tstat', 0),
            'mean_ic': walkforward_results.get('mean_ic', 0),
            'ic_sharpe': walkforward_results.get('ic_sharpe', 0),
            'last_retrain_date': model_results.get('timestamp', 'unknown'),
            'feature_count': len(model_results.get('feature_columns', [])),
            'model_age_days': 1  # Placeholder
        }
        
        # Model health score
        health_factors = [
            min(model_performance['oof_ic'] / 0.008, 1.0),  # IC target 0.8%
            min(model_performance['newey_west_tstat'] / 2.0, 1.0),  # t-stat target 2.0
            min(model_performance['ic_sharpe'] / 0.5, 1.0),  # IC Sharpe target 0.5
            max(1.0 - model_performance['model_age_days'] / 30.0, 0.0)  # Freshness penalty
        ]
        
        model_performance['health_score'] = np.mean(health_factors)
        
        logger.info(f"ü§ñ Model Performance:")
        logger.info(f"   OOF IC: {model_performance['oof_ic']:.4f}")
        logger.info(f"   Health Score: {model_performance['health_score']:.2%}")
        
        return model_performance
    
    def _generate_alerts(self, performance_metrics: Dict, risk_analytics: Dict) -> List[Dict[str, str]]:
        """Generate alerts based on performance and risk metrics"""
        
        logger.info("üö® Generating alerts...")
        
        alerts = []
        
        # Performance alerts
        if 'daily_return_pct' in performance_metrics:
            daily_return = performance_metrics['daily_return_pct']
            
            if daily_return < -2.0:  # More than 2% daily loss
                alerts.append({
                    'type': 'PERFORMANCE',
                    'severity': 'HIGH',
                    'message': f'Large daily loss: {daily_return:.2f}%',
                    'action': 'Review portfolio immediately'
                })
            elif daily_return > 3.0:  # More than 3% daily gain
                alerts.append({
                    'type': 'PERFORMANCE',
                    'severity': 'MEDIUM',
                    'message': f'Large daily gain: {daily_return:.2f}%',
                    'action': 'Verify performance is sustainable'
                })
        
        # Risk alerts
        if 'risk_score' in risk_analytics:
            risk_score = risk_analytics['risk_score']
            
            if risk_score > 0.8:  # Using >80% of risk limits
                alerts.append({
                    'type': 'RISK',
                    'severity': 'HIGH',
                    'message': f'High risk utilization: {risk_score:.1%}',
                    'action': 'Consider reducing position sizes'
                })
            elif risk_score > 0.6:  # Using >60% of risk limits
                alerts.append({
                    'type': 'RISK',
                    'severity': 'MEDIUM',
                    'message': f'Elevated risk utilization: {risk_score:.1%}',
                    'action': 'Monitor closely'
                })
        
        # Concentration alerts
        if 'largest_position' in performance_metrics:
            largest_position = performance_metrics['largest_position']
            if largest_position > 0.04:  # >4% position
                alerts.append({
                    'type': 'CONCENTRATION',
                    'severity': 'MEDIUM',
                    'message': f'Large position detected: {largest_position:.1%}',
                    'action': 'Review position sizing'
                })
        
        # Model alerts (placeholder)
        alerts.append({
            'type': 'MODEL',
            'severity': 'LOW',
            'message': 'Model health normal',
            'action': 'Continue monitoring'
        })
        
        logger.info(f"üö® Generated {len(alerts)} alerts")
        return alerts
    
    def _save_daily_report(self, report: Dict):
        """Save daily report to artifacts"""
        
        logger.info("üíæ Saving daily report...")
        
        # Ensure reports directory exists
        reports_dir = self.artifacts_dir / "reports"
        reports_dir.mkdir(parents=True, exist_ok=True)
        
        # Save JSON report
        report_date = report['date'].replace('-', '')
        report_path = reports_dir / f"daily_report_{report_date}.json"
        
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2, default=str)
        
        logger.info(f"‚úÖ Daily report saved: {report_path}")
    
    def _generate_dashboard(self, report: Dict):
        """Generate HTML dashboard"""
        
        logger.info("üìä Generating dashboard...")
        
        reports_dir = self.artifacts_dir / "reports"
        report_date = report['date'].replace('-', '')
        
        # Create HTML dashboard
        html_content = self._create_dashboard_html(report)
        
        # Save dashboard
        dashboard_path = reports_dir / f"dashboard_{report_date}.html"
        with open(dashboard_path, 'w') as f:
            f.write(html_content)
        
        logger.info(f"üìä Dashboard saved: {dashboard_path}")
    
    def _create_dashboard_html(self, report: Dict) -> str:
        """Create HTML dashboard content"""
        
        performance = report.get('performance_metrics', {})
        attribution = report.get('pnl_attribution', {})
        risk = report.get('risk_analytics', {})
        alerts = report.get('alerts', [])
        
        # Extract key metrics
        daily_pnl = performance.get('total_pnl', 0)
        daily_return = performance.get('daily_return_pct', 0)
        gross_exposure = performance.get('gross_exposure', 0)
        num_positions = performance.get('num_positions', 0)
        
        # Alert styling
        alert_section = ""
        for alert in alerts:
            color = {'HIGH': 'red', 'MEDIUM': 'orange', 'LOW': 'green'}.get(alert['severity'], 'blue')
            alert_section += f"<div style='color: {color}; margin: 5px;'>üö® {alert['message']}</div>"
        
        html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>Daily Performance Dashboard - {report['date']}</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                .metric-box {{ display: inline-block; margin: 10px; padding: 15px; border: 1px solid #ccc; border-radius: 5px; }}
                .positive {{ color: green; }}
                .negative {{ color: red; }}
                .neutral {{ color: blue; }}
                table {{ border-collapse: collapse; width: 100%; }}
                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                th {{ background-color: #f2f2f2; }}
            </style>
        </head>
        <body>
            <h1>Daily Performance Dashboard - {report['date']}</h1>
            
            <h2>Performance Summary</h2>
            <div class="metric-box">
                <h3>Daily P&L</h3>
                <div class="{'positive' if daily_pnl >= 0 else 'negative'}">${daily_pnl:,.0f}</div>
                <div class="{'positive' if daily_return >= 0 else 'negative'}">{daily_return:+.2f}%</div>
            </div>
            
            <div class="metric-box">
                <h3>Exposure</h3>
                <div>Gross: {gross_exposure:.1%}</div>
                <div>Net: {performance.get('net_exposure', 0):.1%}</div>
            </div>
            
            <div class="metric-box">
                <h3>Positions</h3>
                <div>Total: {num_positions}</div>
                <div>Long: {performance.get('num_long', 0)}</div>
                <div>Short: {performance.get('num_short', 0)}</div>
            </div>
            
            <h2>Risk Metrics</h2>
            <div class="metric-box">
                <h3>Risk Score</h3>
                <div>{risk.get('risk_score', 0):.1%}</div>
            </div>
            
            <div class="metric-box">
                <h3>Largest Position</h3>
                <div>{risk.get('risk_metrics', {}).get('largest_position', 0):.2%}</div>
            </div>
            
            <h2>Alerts</h2>
            <div>{alert_section if alert_section else "No alerts"}</div>
            
            <h2>Attribution</h2>
            <p>Top Contributors: {attribution.get('top_contributors', [])}</p>
            <p>Top Detractors: {attribution.get('top_detractors', [])}</p>
            
            <hr>
            <p><small>Generated: {report['timestamp']}</small></p>
        </body>
        </html>
        """
        
        return html

def main():
    """Test the monitoring reporting agent"""
    
    # Load config
    config_path = Path(__file__).parent.parent / "config" / "trading_config.json"
    if config_path.exists():
        with open(config_path, 'r') as f:
            config = json.load(f)
    else:
        logger.error("Trading config not found")
        return False
    
    # Initialize and run agent
    agent = MonitoringReportingAgent(config)
    result = agent.generate_daily_report()
    
    if 'error' not in result:
        print("‚úÖ Daily report generated successfully")
        print(f"üìä Daily P&L: ${result['performance_metrics']['total_pnl']:,.0f}")
        print(f"üìà Daily Return: {result['performance_metrics']['daily_return_pct']:+.2f}%")
        print(f"üö® Alerts: {len(result['alerts'])}")
    else:
        print("‚ùå Daily report generation failed")
        print(f"Error: {result['error']}")
    
    return 'error' not in result

if __name__ == "__main__":
    main()